{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mediapipe as mp\n",
    "import cv2\n",
    "import numpy as np\n",
    "import json\n",
    "import os\n",
    "from fastdtw import fastdtw\n",
    "from scipy.spatial.distance import euclidean\n",
    "import time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üü¢ 'Start' frame matched for 'good'!\n",
      "üü¢ 'Mid1' frame matched for 'good'!\n",
      "üü¢ 'Mid2' frame matched for 'good'!\n",
      "‚úÖ Detected Sign: good\n",
      "üü¢ 'Start' frame matched for 'good'!\n",
      "üü¢ 'Mid1' frame matched for 'good'!\n",
      "üü¢ 'Mid2' frame matched for 'good'!\n",
      "‚úÖ Detected Sign: good\n",
      "üü¢ 'Start' frame matched for 'return'!\n",
      "üü¢ 'Mid1' frame matched for 'return'!\n",
      "üü¢ 'Mid2' frame matched for 'return'!\n",
      "‚úÖ Detected Sign: return\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Initialize Mediapipe\n",
    "mp_hands = mp.solutions.hands\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "\n",
    "TARGET_WIDTH = 320\n",
    "TARGET_HEIGHT = 240\n",
    "cap = cv2.VideoCapture(2)\n",
    "hands = mp_hands.Hands(min_detection_confidence=0.7, min_tracking_confidence=0.7)\n",
    "\n",
    "# File to store gestures\n",
    "GESTURE_FILE = \"gestures.json\"\n",
    "COOLDOWN_TIME = 1  # Cooldown time before detecting the next gesture\n",
    "\n",
    "# Define key landmarks to check\n",
    "keypoints_to_check = [0, 1, 4, 5, 8, 9, 12, 13, 16, 17, 20]\n",
    "\n",
    "# Load existing gestures if available\n",
    "if os.path.exists(GESTURE_FILE):\n",
    "    with open(GESTURE_FILE, \"r\") as f:\n",
    "        gesture_dict = json.load(f)\n",
    "        # Convert each stored frame into a numpy array\n",
    "        gesture_dict = {\n",
    "            k: {\n",
    "                \"start\": np.array(v[\"start\"], dtype=np.float32),\n",
    "                \"mid1\": np.array(v[\"mid1\"], dtype=np.float32),\n",
    "                \"mid2\": np.array(v[\"mid2\"], dtype=np.float32),\n",
    "                \"end\": np.array(v[\"end\"], dtype=np.float32)\n",
    "            }\n",
    "            for k, v in gesture_dict.items()\n",
    "        }\n",
    "else:\n",
    "    gesture_dict = {}\n",
    "\n",
    "# Variables to track sequential matching\n",
    "pending_gesture = None  # The gesture name matched at \"start\"\n",
    "frame_stage = 0         # 0: start, 1: mid1, 2: mid2, 3: end\n",
    "last_detection_time = 0\n",
    "gesture_keyframes={}\n",
    "\n",
    "# New: Stage timeout (in seconds)\n",
    "STAGE_TIMEOUT = 5\n",
    "stage_start_time = None  # Record when the current stage started\n",
    "\n",
    "def normalize_landmarks(landmarks):\n",
    "    \"\"\"Normalize landmarks by centering and scaling relative to the entire hand size.\"\"\"\n",
    "    min_x, min_y, _ = np.min(landmarks, axis=0)\n",
    "    max_x, max_y, _ = np.max(landmarks, axis=0)\n",
    "    center_x = (min_x + max_x) / 2\n",
    "    center_y = (min_y + max_y) / 2\n",
    "    centered_landmarks = landmarks - np.array([center_x, center_y, 0])\n",
    "    hand_width, hand_height = max_x - min_x, max_y - min_y\n",
    "    scale = max(hand_width, hand_height)\n",
    "    if scale > 0:\n",
    "        centered_landmarks /= scale\n",
    "    return centered_landmarks\n",
    "\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    frame = cv2.resize(frame, (TARGET_WIDTH, TARGET_HEIGHT))\n",
    "    rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    results = hands.process(rgb_frame)\n",
    "    current_time = time.time()\n",
    "\n",
    "    # Optional cooldown: skip processing if too soon after last detection\n",
    "    if current_time - last_detection_time < COOLDOWN_TIME:\n",
    "        cv2.imshow(\"Sign Prediction\", frame)\n",
    "        key = cv2.waitKey(1) & 0xFF\n",
    "        if key == ord('q') or key == 27:\n",
    "            break\n",
    "        continue\n",
    "\n",
    "    # If we're in a sequence (frame_stage > 0) but too much time has passed, reset sequence.\n",
    "    if frame_stage > 0 and stage_start_time is not None:\n",
    "        if current_time - stage_start_time > STAGE_TIMEOUT:\n",
    "            print(\"‚è∞ Stage timed out. Resetting sequence.\")\n",
    "            pending_gesture = None\n",
    "            frame_stage = 0\n",
    "            stage_start_time = None\n",
    "\n",
    "    if results.multi_hand_landmarks:\n",
    "        for hand_landmarks in results.multi_hand_landmarks:\n",
    "            mp_drawing.draw_landmarks(frame, hand_landmarks, mp_hands.HAND_CONNECTIONS)\n",
    "            landmarks = np.array([(lm.x, lm.y, lm.z) for lm in hand_landmarks.landmark],\n",
    "                                 dtype=np.float32)\n",
    "            if landmarks.shape[0] < max(keypoints_to_check):\n",
    "                continue  # Incomplete detection; skip this frame\n",
    "\n",
    "            normalized_landmarks = normalize_landmarks(landmarks)\n",
    "            normalized_keypoints = normalized_landmarks[keypoints_to_check]\n",
    "            frame_sequence = [\"start\", \"mid1\", \"mid2\", \"end\"]\n",
    "\n",
    "            # For the first stage, if no sequence is started, try to match \"start\"\n",
    "            if frame_stage == 0:\n",
    "                for gesture_name, frames in gesture_dict.items():\n",
    "                    keyframe_points = frames[\"start\"].reshape(-1, 3)\n",
    "                    if keyframe_points.shape != normalized_keypoints.shape:\n",
    "                        continue\n",
    "                    distance, _ = fastdtw(keyframe_points, normalized_keypoints, dist=euclidean)\n",
    "                    if distance < 1:\n",
    "                        pending_gesture = gesture_name\n",
    "                        frame_stage = 1\n",
    "                        stage_start_time = current_time  # Start timing this stage\n",
    "                        print(f\"üü¢ 'Start' frame matched for '{gesture_name}'!\")\n",
    "                        break\n",
    "\n",
    "            # For subsequent stages, use the pending gesture's corresponding frame\n",
    "            elif pending_gesture:\n",
    "                stage_name = frame_sequence[frame_stage]\n",
    "                keyframe_points = gesture_dict[pending_gesture][stage_name].reshape(-1, 3)\n",
    "                if keyframe_points.shape == normalized_keypoints.shape:\n",
    "                    distance, _ = fastdtw(keyframe_points, normalized_keypoints, dist=euclidean)\n",
    "                    if distance < 1:\n",
    "                        print(f\"üü¢ '{stage_name.capitalize()}' frame matched for '{pending_gesture}'!\")\n",
    "                        frame_stage += 1\n",
    "                        stage_start_time = current_time  # Reset timer for next stage\n",
    "                        if frame_stage == 3:  # All stages matched\n",
    "                            print(f\"‚úÖ Detected Sign: {pending_gesture}\")\n",
    "                            last_detection_time = current_time\n",
    "                            pending_gesture = None\n",
    "                            frame_stage = 0  # Reset for next gesture detection\n",
    "                            stage_start_time = None\n",
    "                            break  # Stop processing further for this hand\n",
    "\n",
    "    # Handle key presses to record frames or quit\n",
    "    key = cv2.waitKey(1) & 0xFF\n",
    "    if key == ord('1'):\n",
    "        if results.multi_hand_landmarks:\n",
    "            gesture_keyframes[\"start\"] = normalize_landmarks(landmarks)[keypoints_to_check].copy()\n",
    "            print(\"‚úÖ Start frame recorded!\")\n",
    "    elif key == ord('2'):\n",
    "        if results.multi_hand_landmarks:\n",
    "            gesture_keyframes[\"mid1\"] = normalize_landmarks(landmarks)[keypoints_to_check].copy()\n",
    "            print(\"‚úÖ Mid1 frame recorded!\")\n",
    "    elif key == ord('3'):\n",
    "        if results.multi_hand_landmarks:\n",
    "            gesture_keyframes[\"mid2\"] = normalize_landmarks(landmarks)[keypoints_to_check].copy()\n",
    "            print(\"‚úÖ Mid2 frame recorded!\")\n",
    "    elif key == ord('4'):\n",
    "        if results.multi_hand_landmarks:\n",
    "            gesture_keyframes[\"end\"] = normalize_landmarks(landmarks)[keypoints_to_check].copy()\n",
    "            print(\"‚úÖ End frame recorded!\")\n",
    "            gesture_name = input(\"Enter the word for this sign: \")\n",
    "            gesture_dict[gesture_name] = gesture_keyframes.copy()\n",
    "            with open(GESTURE_FILE, \"w\") as f:\n",
    "                json.dump(\n",
    "                    {k: {frame: v.tolist() for frame, v in frames.items()} for k, frames in gesture_dict.items()},\n",
    "                    f\n",
    "                )\n",
    "            print(f\"üìÅ Sign '{gesture_name}' saved permanently!\")\n",
    "    elif key == ord('q') or key == 27:\n",
    "        break\n",
    "\n",
    "    cv2.imshow(\"Sign Prediction\", frame)\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
